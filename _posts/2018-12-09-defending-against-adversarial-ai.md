---
title: Defending against adversarial artificial intelligence
date: 2018-12-09
category: theory
lang: en
image: security_ai.png
---
notes from [medium](https://medium.com/onfido-tech/adversarial-attacks-and-defences-for-convolutional-neural-networks-66915ece52e7)
[publication](https://arxiv.org/pdf/1812.03411.pdf) and [goodfello's publication](https://arxiv.org/pdf/1812.03411.pdf)
![]({{ site.baseurl }}/static/img/security_ai.png)

While Industry 4.0 is all about AI, security and IIOT, few talk about security of AI.

This little talked about topic allows attacker to use knowledge of AI used for image recognition to inject noise unseen by humans and lead machines to the wrong conclusions.

FAIR & John Hopkins Researchers have now made significant progress leading to 50% accuracy (nearly double from previous best score).

### Questions:
* Can Road-signs be "tampered" in a way which achieves this effect?
* can masks be printed (Mission Impossible style) to achieve false ID?
